{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "        'Topic sentences are similar to mini thesis statements.\\\n",
    "        Like a thesis statement, a topic sentence has a specific \\\n",
    "        main point. Whereas the thesis is the main point of the essay',\\\n",
    "        'the topic sentence is the main point of the paragraph.\\\n",
    "        Like the thesis statement, a topic sentence has a unifying function. \\\n",
    "        But a thesis statement or topic sentence alone doesnâ€™t guarantee unity.', \\\n",
    "        'An essay is unified if all the paragraphs relate to the thesis,\\\n",
    "        whereas a paragraph is unified if all the sentences relate to the topic sentence.'\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list()\n",
    "word_set = list()\n",
    "\n",
    "for sent in text:\n",
    "    x = [i.lower() for i in word_tokenize(sent) if i.isalpha()]\n",
    "    sentences.append(x)\n",
    "    for word in x:\n",
    "        if word not in word_set:\n",
    "            word_set.append(word)\n",
    "\n",
    "# Set of vocabulary\n",
    "word_set = set(word_set)\n",
    "\n",
    "# Total elements in our corpus\n",
    "total_documents = len(sentences)\n",
    "\n",
    "# Creating an index for each word in the vocabulary.\n",
    "index_dict = dict()\n",
    "i = 0\n",
    "\n",
    "for word in word_set:\n",
    "    index_dict[word] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['topic',\n",
       "  'sentences',\n",
       "  'are',\n",
       "  'similar',\n",
       "  'to',\n",
       "  'mini',\n",
       "  'thesis',\n",
       "  'statements',\n",
       "  'like',\n",
       "  'a',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'a',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'has',\n",
       "  'a',\n",
       "  'specific',\n",
       "  'main',\n",
       "  'point',\n",
       "  'whereas',\n",
       "  'the',\n",
       "  'thesis',\n",
       "  'is',\n",
       "  'the',\n",
       "  'main',\n",
       "  'point',\n",
       "  'of',\n",
       "  'the',\n",
       "  'essay'],\n",
       " ['the',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'is',\n",
       "  'the',\n",
       "  'main',\n",
       "  'point',\n",
       "  'of',\n",
       "  'the',\n",
       "  'paragraph',\n",
       "  'like',\n",
       "  'the',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'a',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'has',\n",
       "  'a',\n",
       "  'unifying',\n",
       "  'function',\n",
       "  'but',\n",
       "  'a',\n",
       "  'thesis',\n",
       "  'statement',\n",
       "  'or',\n",
       "  'topic',\n",
       "  'sentence',\n",
       "  'alone',\n",
       "  'doesn',\n",
       "  't',\n",
       "  'guarantee',\n",
       "  'unity'],\n",
       " ['an',\n",
       "  'essay',\n",
       "  'is',\n",
       "  'unified',\n",
       "  'if',\n",
       "  'all',\n",
       "  'the',\n",
       "  'paragraphs',\n",
       "  'relate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'thesis',\n",
       "  'whereas',\n",
       "  'a',\n",
       "  'paragraph',\n",
       "  'is',\n",
       "  'unified',\n",
       "  'if',\n",
       "  'all',\n",
       "  'the',\n",
       "  'sentences',\n",
       "  'relate',\n",
       "  'to',\n",
       "  'the',\n",
       "  'topic',\n",
       "  'sentence']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'all',\n",
       " 'alone',\n",
       " 'an',\n",
       " 'are',\n",
       " 'but',\n",
       " 'doesn',\n",
       " 'essay',\n",
       " 'function',\n",
       " 'guarantee',\n",
       " 'has',\n",
       " 'if',\n",
       " 'is',\n",
       " 'like',\n",
       " 'main',\n",
       " 'mini',\n",
       " 'of',\n",
       " 'or',\n",
       " 'paragraph',\n",
       " 'paragraphs',\n",
       " 'point',\n",
       " 'relate',\n",
       " 'sentence',\n",
       " 'sentences',\n",
       " 'similar',\n",
       " 'specific',\n",
       " 'statement',\n",
       " 'statements',\n",
       " 't',\n",
       " 'the',\n",
       " 'thesis',\n",
       " 'to',\n",
       " 'topic',\n",
       " 'unified',\n",
       " 'unifying',\n",
       " 'unity',\n",
       " 'whereas'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, set)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentences), type(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 37)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences), len(word_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a count dictionary\n",
    "\n",
    "def count_dict(sentences):\n",
    "    word_count = dict()\n",
    "\n",
    "    for word in word_set:\n",
    "        word_count[word] = 0\n",
    "        for sent in sentences:\n",
    "            if word in sent:\n",
    "                word_count[word] += 1\n",
    "    \n",
    "    return word_count\n",
    "\n",
    "word_count = count_dict(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 3,\n",
       " 'but': 1,\n",
       " 'sentences': 2,\n",
       " 'statements': 1,\n",
       " 'guarantee': 1,\n",
       " 'thesis': 3,\n",
       " 'or': 1,\n",
       " 'has': 2,\n",
       " 'unifying': 1,\n",
       " 'an': 1,\n",
       " 't': 1,\n",
       " 'relate': 1,\n",
       " 'like': 2,\n",
       " 'if': 1,\n",
       " 'to': 2,\n",
       " 'the': 3,\n",
       " 'is': 3,\n",
       " 'a': 3,\n",
       " 'doesn': 1,\n",
       " 'unified': 1,\n",
       " 'paragraphs': 1,\n",
       " 'function': 1,\n",
       " 'mini': 1,\n",
       " 'of': 2,\n",
       " 'statement': 2,\n",
       " 'alone': 1,\n",
       " 'topic': 3,\n",
       " 'all': 1,\n",
       " 'specific': 1,\n",
       " 'point': 2,\n",
       " 'are': 1,\n",
       " 'essay': 2,\n",
       " 'similar': 1,\n",
       " 'unity': 1,\n",
       " 'main': 2,\n",
       " 'paragraph': 2,\n",
       " 'whereas': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF - Term Frequency\n",
    "# count of t in d / no of words in d\n",
    "\n",
    "def term_freq(document, word):\n",
    "    n = len(document)\n",
    "    occurence = len([token for token in document if token == word])\n",
    "\n",
    "    return occurence / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDF - Inverse Document Frequency\n",
    "# log(n / (df + 1))\n",
    "\n",
    "def inv_doc_freq(word):\n",
    "    try:\n",
    "        word_occurence = word_count[word] + 1\n",
    "    except:\n",
    "        word_occurence = 1\n",
    "\n",
    "    return np.log(total_documents / word_occurence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "\n",
    "def tf_idf(sentence):\n",
    "    tf_idf_vec = np.zeros((len(word_set),))\n",
    "\n",
    "    for word in sentence:\n",
    "        tf = term_freq(sentence, word)\n",
    "        idf = inv_doc_freq(word)\n",
    "\n",
    "        value = tf * idf\n",
    "        tf_idf_vec[index_dict[word]] = value\n",
    "\n",
    "    return tf_idf_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.0095894 ,  0.        ,  0.        ,  0.0135155 ,  0.        ,\n",
      "       -0.02876821,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.02876821, -0.0095894 , -0.02876821,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.0135155 ,  0.        ,  0.        ,\n",
      "        0.        , -0.0191788 ,  0.        ,  0.0135155 ,  0.        ,\n",
      "        0.0135155 ,  0.        ,  0.0135155 ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ]), array([-0.02615292,  0.01228682,  0.        ,  0.        ,  0.01228682,\n",
      "       -0.01743528,  0.01228682,  0.        ,  0.01228682,  0.        ,\n",
      "        0.01228682,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.03487055, -0.00871764, -0.02615292,  0.01228682,  0.        ,\n",
      "        0.        ,  0.01228682,  0.        ,  0.        ,  0.        ,\n",
      "        0.01228682, -0.02615292,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.01228682,  0.        ,\n",
      "        0.        ,  0.        ]), array([-0.0110647 ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "       -0.0110647 ,  0.        ,  0.        ,  0.        ,  0.01559481,\n",
      "        0.        ,  0.03118962,  0.        ,  0.03118962,  0.        ,\n",
      "       -0.04425878, -0.02212939, -0.0110647 ,  0.        ,  0.03118962,\n",
      "        0.01559481,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        , -0.0110647 ,  0.03118962,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
      "        0.        ,  0.        ])]\n"
     ]
    }
   ],
   "source": [
    "vectors = list()\n",
    "\n",
    "for sent in sentences:\n",
    "    vec = tf_idf(sent)\n",
    "    vectors.append(vec)\n",
    "\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
